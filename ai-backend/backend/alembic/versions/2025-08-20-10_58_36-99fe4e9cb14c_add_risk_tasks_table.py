"""add_risk_tasks_table

Revision ID: 99fe4e9cb14c
Revises: 7e1a5600c498
Create Date: 2025-08-20 10:58:36.966066

"""

import sqlalchemy as sa

from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = "99fe4e9cb14c"
down_revision = "7e1a5600c498"
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "risk_tasks",
        sa.Column("task_id", sa.String(length=64), nullable=False, comment="任务唯一标识，UUID格式"),
        sa.Column("task_type", sa.Enum("PAYMENT_RISK", name="tasktype"), nullable=True, comment="任务类型"),
        sa.Column(
            "status",
            sa.Enum("PENDING", "PROCESSING", "COMPLETED", "FAILED", name="taskstatus"),
            nullable=True,
            comment="任务状态",
        ),
        sa.Column("member_id", sa.Integer(), nullable=False, comment="用户ID"),
        sa.Column("progress", sa.Integer(), nullable=True, comment="进度百分比(0-100)"),
        sa.Column("message", sa.Text(), nullable=True, comment="状态描述信息"),
        sa.Column("report_id", sa.Integer(), nullable=True, comment="报告日志ID"),
        sa.Column("request_data", sa.JSON(), nullable=True, comment="原始请求参数（payment_info等）"),
        sa.Column("risk_score", sa.DECIMAL(precision=5, scale=2), nullable=True, comment="风险评分 0.00-100.00"),
        sa.Column("risk_level", sa.Enum("LOW", "MEDIUM", "HIGH", name="risklevel"), nullable=True, comment="风险等级"),
        sa.Column("analysis_result", sa.JSON(), nullable=True, comment="详细分析结果"),
        sa.Column("error_message", sa.Text(), nullable=True, comment="失败时的错误信息"),
        sa.Column("retry_count", sa.Integer(), nullable=True, comment="重试次数"),
        sa.Column("created_at", sa.DateTime(), nullable=True, comment="任务创建时间"),
        sa.Column("updated_at", sa.DateTime(), nullable=True, comment="任务更新时间"),
        sa.Column("completed_at", sa.DateTime(), nullable=True, comment="任务完成时间"),
        sa.Column("created_time", sa.DateTime(timezone=True), nullable=False, comment="创建时间"),
        sa.Column("updated_time", sa.DateTime(timezone=True), nullable=True, comment="更新时间"),
        sa.PrimaryKeyConstraint("task_id"),
        comment="风险任务表",
    )
    op.create_index("idx_risk_tasks_created_at", "risk_tasks", ["created_at"], unique=False)
    op.create_index("idx_risk_tasks_member_id", "risk_tasks", ["member_id"], unique=False)
    op.create_index("idx_risk_tasks_status", "risk_tasks", ["status"], unique=False)
    op.create_index("idx_risk_tasks_task_type_status", "risk_tasks", ["task_type", "status"], unique=False)

    # 安全删除表 - 只有在表存在时才删除
    connection = op.get_bind()
    inspector = sa.inspect(connection)
    existing_tables = inspector.get_table_names()

    if "task_result" in existing_tables:
        op.drop_table("task_result")
    if "task_group_result" in existing_tables:
        op.drop_table("task_group_result")
    op.alter_column(
        "ai_chat_file",
        "created_time",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        comment="创建时间",
        existing_nullable=False,
    )
    op.alter_column(
        "ai_chat_file",
        "updated_time",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        comment="更新时间",
        existing_nullable=True,
    )
    # 安全处理 ai_chat_file 表的索引和约束
    if "ai_chat_file" in existing_tables:
        # 安全删除索引 - 只有在索引存在时才删除
        existing_indexes = inspector.get_indexes("ai_chat_file")
        index_names = [idx["name"] for idx in existing_indexes]

        if "ix_ai_chat_file_data_source" in index_names:
            op.drop_index(op.f("ix_ai_chat_file_data_source"), table_name="ai_chat_file")
        if "ix_ai_chat_file_task_id" in index_names:
            op.drop_index(op.f("ix_ai_chat_file_task_id"), table_name="ai_chat_file")

        # 安全删除外键约束 - 只有在约束存在时才删除和重建
        existing_fks = inspector.get_foreign_keys("ai_chat_file")
        fk_names = [fk["name"] for fk in existing_fks]

        if "ai_chat_file_chat_message_id_fkey" in fk_names:
            op.drop_constraint(op.f("ai_chat_file_chat_message_id_fkey"), "ai_chat_file", type_="foreignkey")
            op.create_foreign_key(None, "ai_chat_file", "ai_chat_message", ["chat_message_id"], ["id"])
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, "ai_chat_file", type_="foreignkey")
    op.create_foreign_key(
        op.f("ai_chat_file_chat_message_id_fkey"),
        "ai_chat_file",
        "ai_chat_message",
        ["chat_message_id"],
        ["id"],
        ondelete="CASCADE",
    )
    op.create_index(op.f("ix_ai_chat_file_task_id"), "ai_chat_file", ["task_id"], unique=False)
    op.create_index(op.f("ix_ai_chat_file_data_source"), "ai_chat_file", ["data_source"], unique=False)
    op.alter_column(
        "ai_chat_file",
        "updated_time",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        comment=None,
        existing_comment="更新时间",
        existing_nullable=True,
    )
    op.alter_column(
        "ai_chat_file",
        "created_time",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        comment=None,
        existing_comment="创建时间",
        existing_nullable=False,
    )
    op.create_table(
        "task_group_result",
        sa.Column("id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("taskset_id", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("result", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("date_done", postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name=op.f("task_group_result_pkey")),
        sa.UniqueConstraint(
            "taskset_id",
            name=op.f("task_group_result_taskset_id_key"),
            postgresql_include=[],
            postgresql_nulls_not_distinct=False,
        ),
    )
    op.create_table(
        "task_result",
        sa.Column("id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("task_id", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("status", sa.VARCHAR(length=50), autoincrement=False, nullable=True),
        sa.Column("result", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("date_done", postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
        sa.Column("traceback", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column("name", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("args", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("kwargs", postgresql.BYTEA(), autoincrement=False, nullable=True),
        sa.Column("worker", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.Column("retries", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column("queue", sa.VARCHAR(length=155), autoincrement=False, nullable=True),
        sa.PrimaryKeyConstraint("id", name=op.f("task_result_pkey")),
        sa.UniqueConstraint(
            "task_id", name=op.f("task_result_task_id_key"), postgresql_include=[], postgresql_nulls_not_distinct=False
        ),
    )
    op.drop_index("idx_risk_tasks_task_type_status", table_name="risk_tasks")
    op.drop_index("idx_risk_tasks_status", table_name="risk_tasks")
    op.drop_index("idx_risk_tasks_member_id", table_name="risk_tasks")
    op.drop_index("idx_risk_tasks_created_at", table_name="risk_tasks")
    op.drop_table("risk_tasks")
    # ### end Alembic commands ###
